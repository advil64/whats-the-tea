{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63b05bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext #Import streaming context\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import spacy\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.functions import array_to_vector\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import spacy\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "tqdm.pandas()\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527ea27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/koko/system/spark-3.2.1-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/12/07 13:45:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .master('local[*]')\\\n",
    "    .appName('explore')\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext._conf.setAll([('spark.driver.maxResultSize', '8g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3dd0174-4210-42a3-b2e0-baed15b507cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.json('/common/users/shared/cs543_fall22_group3/combined/combined_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e1cf57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text):\n",
    "    return ','.join(nlp(str(text)).vector)\n",
    "\n",
    "vectorize_udf = F.udf(lambda z: vectorize(z))\n",
    "processed_df = df.withColumn(\"vector\", F.split(vectorize_udf(F.col(\"selected_text\")), \",\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08b189c4-d3da-45fe-840d-f9ca87fb9414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- selected_text: string (nullable = true)\n",
      " |-- vector: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "processed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dac18c9-e4b2-46f9-95d8-be7a3be4846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, num_class, embed_dim=300, vocab_size=45, pad_index=0,\n",
    "                 stride=1, kernel_size=3, conv_out_size=64, dropout_rate=0.25):\n",
    "        super(TextClassificationModel, self).__init__()\n",
    "\n",
    "        # Embedding layer parameters\n",
    "        self.embed_size = embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.pad_index = pad_index\n",
    "       \n",
    "        # Conv layer parameters\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv_out_size = conv_out_size\n",
    "       \n",
    "        # Misc\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.embed_size = 1\n",
    "        # Layers\n",
    "        self.conv = torch.nn.Conv1d(self.embed_size, self.conv_out_size, self.kernel_size, self.stride)\n",
    "        self.hidden_act = torch.relu\n",
    "        self.max_pool = torch.nn.MaxPool1d(self.kernel_size, self.stride)\n",
    "       \n",
    "        self.flatten = lambda x: x.view(x.shape[0], x.shape[1]*x.shape[2])\n",
    "       \n",
    "        self.fc = torch.nn.Linear(self._linear_layer_in_size(), num_class)\n",
    "\n",
    "        if self.dropout_rate:\n",
    "            self.dropout = torch.nn.Dropout(self.dropout_rate)\n",
    "\n",
    "    def _linear_layer_in_size(self):\n",
    "        out_conv_1 = ((self.embed_size - 1 * (self.kernel_size - 1) - 1) / self.stride) + 1\n",
    "        out_conv_1 = math.floor(out_conv_1)\n",
    "        out_pool_1 = ((out_conv_1 - 1 * (self.kernel_size - 1) - 1) / self.stride) + 1\n",
    "        out_pool_1 = math.floor(out_pool_1)\n",
    "                           \n",
    "        # return out_pool_1*self.conv_out_size\n",
    "        return 18944\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "\n",
    "        # x = torch.reshape(x. (x.shape[0],)\n",
    "\n",
    "        x = torch.unsqueeze(x, 1)\n",
    "        # x = torch.transpose(x, 1, 2) # (batch, 1, 300)\n",
    "\n",
    "        x = self.conv(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.hidden_act(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.max_pool(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        if self.dropout_rate:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0344b4e-f741-4426-883c-21089c6829ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "m = TextClassificationModel(300, 42)\n",
    "m.load_state_dict(torch.load('/common/users/shared/cs543_fall22_group3/models/class_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59f934ac-7e9b-41fa-96de-c769cf40f237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationModel(\n",
       "  (conv): Conv1d(1, 64, kernel_size=(3,), stride=(1,))\n",
       "  (max_pool): MaxPool1d(kernel_size=3, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): Linear(in_features=18944, out_features=300, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8c0c839-2c58-43c9-a0ea-41765b91f86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(96,), dtype=float32, numpy=\n",
       "array([ 0.08313738,  0.23493402,  0.50700295,  0.20518368, -0.61994565,\n",
       "       -0.31686923, -0.38639998, -0.47822252,  0.2874061 ,  0.5616789 ,\n",
       "        0.27226388,  0.23311011,  0.42662886, -0.45091665, -0.0188958 ,\n",
       "       -0.04201526,  0.51277566, -0.22706264, -0.32356876,  0.1642192 ,\n",
       "       -0.02346741,  0.01970796,  0.12345982,  0.369655  , -0.18727557,\n",
       "       -0.22674748,  0.92299557,  0.17571642, -0.04334598,  0.12421735,\n",
       "       -0.39291257,  0.2203804 , -0.08235582, -0.09592929,  0.5930834 ,\n",
       "       -0.35781085,  0.49502695, -0.15281105, -0.5987592 ,  0.3305167 ,\n",
       "        0.25534928,  0.23432654,  0.1319402 , -0.5745461 , -0.42265713,\n",
       "       -0.00779722,  0.0778453 ,  0.54223657,  0.05138373,  0.3120443 ,\n",
       "        0.03517745, -0.3613884 , -0.32268447, -0.6085768 , -0.31113058,\n",
       "        0.32031095,  0.83841497, -0.47435936, -0.4444853 , -0.11046734,\n",
       "       -0.00772311, -0.46004343,  0.3659531 , -0.4661703 , -0.31928566,\n",
       "        0.03663981,  0.05994961,  0.07785396, -0.85782146, -0.7176973 ,\n",
       "        0.08220021,  0.04260971, -0.10091164,  0.23546632, -0.4407573 ,\n",
       "        0.6568574 , -0.09895972,  0.32152116, -0.46863058,  0.29226652,\n",
       "       -0.03714588, -0.6926199 ,  0.47678763,  0.38801876,  0.4663656 ,\n",
       "        0.06836712,  0.3824191 , -0.01191635,  0.06844462,  0.22185756,\n",
       "       -0.75744253, -0.75920415, -0.18869206,  0.47167173, -0.11798266,\n",
       "       -0.32620043], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a13e757-68b4-4809-9801-dc361bc545ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 1, 3], expected input[1, 96, 1] to have 1 channels, but got 96 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-d738d02d3220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8e5034c6ad24>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# x = torch.transpose(x, 1, 2) # (batch, 1, 300)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 309\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    310\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 1, 3], expected input[1, 96, 1] to have 1 channels, but got 96 channels instead"
     ]
    }
   ],
   "source": [
    "m(torch.from_numpy(np.array(df.take(1)[0].vector, dtype=np.float32)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
